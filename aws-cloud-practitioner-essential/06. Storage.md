# Storage

## S3 (Simple Storage Service)

Provides various storage classes to suit variety of workloads with specific performance, access, resiliency and cost requirements.
data residency
unpredicatable access pattern
archival needs
most cost effective option for different access patterns

### S3 standard

S3 Standard is considered general-purpose storage for cloud applications, dynamic websites, content distribution, mobile and gaming applications, and big data analytics. When you upload an object to Amazon S3 without specifying a storage class, the object is added to S3 Standard by default.

### S3 Intelligent-Tiering

This tier is useful if your data has unknown or changing access patterns. S3 Intelligent-Tiering stores objects in three tiers: a frequent access tier, an infrequent access tier, and an archive instant access tier. Amazon S3 monitors access patterns of your data and automatically moves your data to the most cost-effective storage tier based on frequency of access.

### S3 Standard Infrequent Access (Standard-IA)

S3 Standard-Infrequent Access (S3 Standard-IA) is for data that is accessed less frequently but requires rapid access when needed. S3 Standard-IA offers the high durability, high throughput, and low latency of S3 Standard, with a low per-GiB storage price and per-GiB retrieval fee. This storage tier is ideal if you want to store long-term backups, disaster recovery files, and so on.

### S3 One Zone Infrequent Access (One Zone-IA)

S3 One Zone-Infrequent Access (S3 One Zone-IA) stores data in a single Availability Zone, reducing costs compared to S3 Standard-IA, which uses three zones. This storage class suits customers seeking affordable storage for infrequently accessed data without high availability needs. It's perfect for storing secondary backups or easily recreatable data.

### S3 Express One Zone

S3 Express One Zone stores data in a single Availability Zone. It was purpose-built to deliver consistent single-digit millisecond data access for your most frequently accessed data and latency-sensitive applications. S3 Express One Zone delivers data access speed up to 10x faster and request costs up to 80% lower than S3 Standard.

### S3 Glacier Instant Retrieval

Use S3 Glacier Instant Retrieval for archiving data that is rarely accessed and requires millisecond retrieval. Data stored in this storage class offers a cost savings of up to 68 percent compared to the S3 Standard-IA storage class, with the same latency and throughput performance.

### S3 Glacier Flexible Retrieval

S3 Glacier Flexible Retrieval offers low-cost storage for archived data that is accessed 1–2 times per year. With S3 Glacier Flexible Retrieval, your data can be accessed in as little as 1–5 minutes using an expedited retrieval. You can also request bulk retrievals in up to 5–12 hours at no additional cost. It's an ideal solution for backup, disaster recovery, offsite data storage needs, and for when some data occasionally must be retrieved in minutes.

### S3 Glacier Deep Archive

S3 Glacier Deep Archive is the lowest-cost Amazon S3 storage class. It supports long-term retention and digital preservation for data that might be accessed once or twice per year. Data stored in the S3 Glacier Deep Archive storage class has a default retrieval time of 12 hours. It is designed for customers that retain data sets for 7–10 years or longer, to meet regulatory compliance requirements. Examples include those in highly regulated industries, such as financial services, healthcare, and public sectors.

### S3 Outposts

Amazon S3 Outposts delivers object storage to your on-premises AWS Outposts environment using Amazon S3 APIs and features, and serves workloads with local data residency requirements. It also helps maintain optimal performance when data must remain in close proximity to on-premises applications.

### S3 Lifecycle

![alt text](S3LifecycleFlow.png)

## Amazon EFS (elastic file system)

Fully managed, scalable file storage service for use with AWS cloud services and on-premises resources.  It operates using the **Linux Network File System (NFS)** protocol, and automatically scales to petabytes as you add or remove files without disrupting applications. EFS is designed to support a wide variety of workloads and can be accessed by multiple EC2 instances simultaneously.

### Benefits

- Multi zone redundancy
- Shared Access
- Elastic Storage - Amazon EFS supports thousands of concurrent NFS connections
- Elastic Storage

### Amazon EFS storage classes

- Standard storage classes
  - EFS Standard 
  - EFS Standard-Infrequent Access (Standard-IA) 
- One Zone Storage Classes
  - EFS One Zone
  - EFS One Zone-Infrequent Access (EFS One Zone-IA) 
- Archive storage class 

### Lifecycle

- Transition to IA
- Transition to Archive
- Transition to Standard

## FSx

Amazon FSx makes it convenient and cost effective to launch, run, and scale feature-rich, high-performance file systems in the cloud. It supports a wide range of workloads with its reliability, security, scalability, and broad set of capabilities. Compared to Amazon EFS, which focuses on the Network File System (NFS) compatibility, Amazon FSx supports multiple filesystem protocols, including Windows File Server, Lustre, OpenZFS, and NetAPP ONTAP.

Amazon FSx is built on the latest AWS compute, networking, and disk technologies to provide high performance and lower total cost of ownership (TCO). As a fully managed service, it handles hardware provisioning, patching, and backups.

### Benefits

- File System integration - Amazon FSx supports industry-standard file system protocols, allowing convenient integration with your existing applications, workflows, and development tools.
- Managed infrastructure
- Scalable storage
- Cost effective

#### Amazon FSx for Lustre

Amazon FSx for Lustre provides fully managed shared storage with the scalability and performance of the popular Lustre file system.

Use cases include the following:

- Accelerate machine learning (ML).
- Enable high performance computing (HPC).
- Unlock big data analytics.
- Increase media workload agility.

## AWS Storage Gateway

Storage Gateway is a hybrid cloud storage service that makes it possible to seamlessly integrate on-premises environments with AWS Cloud storage. You can use it to extend your local storage to the cloud while maintaining low-latency access to frequently used data.

You can use Storage Gateway to streamline storage management and reduce costs for practical hybrid cloud storage use cases. These include moving backups to the cloud, using on-premises file shares backed by cloud storage, and providing low-latency access to data in AWS for on-premises applications.

### Benefits

- Seamless integration - Storage Gateway enables smooth connectivity between on-premises applications and AWS Cloud storage, preserving existing workflows and minimizing disruption.
- Improved data management - Storage Gateway provides centralized management of hybrid storage environments, enhancing accessibility, security, and compliance.
- Local caching - Storage Gateway locally keeps frequently accessed data for quick access while managing less-used data in the cloud.
- cost optimization - Storage Gateway reduces on-premises storage costs by using cloud storage for data archiving, backup, and disaster recovery purposes.

### Gateway types

- Amazon S3 File Gateway -When you deploy an S3 File Gateway, it appears to your local systems as a standard file server.
- Volume Gateway - It essentially functions as a bridge between your on-premises infrastructure and AWS Cloud storage by presenting your cloud data as iSCSI volumes that can be mounted by your existing applications. It has two modes -
  - Cached volume mode stores primary data in the cloud while frequently accessed data is cached locally for low-latency access.
  - Stored volume mode locally keeps your complete dataset while asynchronously backing it up to the cloud as EBS snapshots.
- Tape Gateway - backup to virtual tape using same software that was writing to tape

## AWS disaster recovery

Elastic Disaster Recovery replicates critical workloads to AWS with minimal downtime. Your servers' block-level data is continuously replicated to AWS, making it ideal for uses that require robust disaster recovery solutions. It supports both physical and virtual servers to enable rapid recovery during disruptions, which is particularly valuable for industries like healthcare where system availability is crucial.